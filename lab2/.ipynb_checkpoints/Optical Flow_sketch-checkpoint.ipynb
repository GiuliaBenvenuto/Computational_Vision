{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  SURNAME: Benvenuto NAME: Giulia\n",
    "#### **I cleared all the outputs because otherwise the size of the notebook was too big to be uploaded on aulaweb.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv2\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "from visualize_flow import flow_to_color\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Lucas-Kanade optical flow algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab we deepen our understanding on the Lucas Kanade (LK) optical flow algorithm. \n",
    "\n",
    "<ol>\n",
    "    <li>Part 1: we go into the <b>implementation details</b> of a single scale estimation (the one we saw in class) </li>\n",
    "    <li>Part 2 (optional): we will use the <b>pre-implemented </b> algorithm (OpenCV) for a multi-resolution pyramidal version.</li>\n",
    "</ol>\n",
    " \n",
    "### Part1 - Single Scale LK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we start by loading a pair of adjacent frames\n",
    "#img1= cv2.imread('Data/stennis/stennis_002.ppm', cv2.IMREAD_GRAYSCALE)\n",
    "#img2= cv2.imread('Data/stennis/stennis_003.ppm', cv2.IMREAD_GRAYSCALE)\n",
    "img1= cv2.imread('Data/sphere/sphere.12.ppm', cv2.IMREAD_GRAYSCALE)\n",
    "img2= cv2.imread('Data/sphere/sphere.13.ppm', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Fill in the missing details on the Lucas_Kanade function, after you analyse and understand what's already there: </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function computes the optical flow between 2 frames\n",
    "\n",
    "# Takes as inputs two grayscale images im1 and im2 taken at times t1 and t2, a window size window_size (odd) that controls the size \n",
    "# of the pixel neighbourhoodand tau that is a threshould on the \"quality\" of the neighbourhood\n",
    "def Lucas_Kanade(im1, im2, window_size, tau):\n",
    "    \n",
    "    # Spatio-temporal derivative kernels: the derivative of an image is a measure of how quickly the image intensity changes in \n",
    "    # different directions. Therefore, the derivative kernel highlights the areas where the image intensity changes rapidly in a \n",
    "    # particular direction, here we use these kernels to find the corners.\n",
    "    kernel_x = np.array([[-1., 1.], [-1., 1.]])*.25 \n",
    "    kernel_y = np.array([[-1., -1.], [1., 1.]])*.25\n",
    "    kernel_t = np.array([[1., 1.], [1., 1.]])*.25\n",
    "    \n",
    "    # window_size is odd, all the pixels with offset in between [-w, w] are inside the window\n",
    "    w = int(window_size/2) \n",
    "    \n",
    "    # Normalization of the image pixel values to a range of 0 - 1.\n",
    "    I1g = im1 / 255. # normalize pixels\n",
    "    I2g = im2 / 255. # normalize pixels\n",
    "    \n",
    "    \n",
    "    # Implement Lucas Kanade\n",
    "    # for each point, calculate I_x, I_y, I_t\n",
    "    \n",
    "    # Applying the kernels convolving them with the image and we get back the derivatives in space (fx and fy) and time (ft)\n",
    "    mode = 'same'\n",
    "    fx = signal.convolve2d(I1g, kernel_x, boundary='symm', mode=mode)# + signal.convolve2d(I2g, kernel_x, boundary='symm', mode=mode)\n",
    "    fy = signal.convolve2d(I1g, kernel_y, boundary='symm', mode=mode)# + signal.convolve2d(I2g, kernel_y, boundary='symm', mode=mode) \n",
    "    ft = signal.convolve2d(I1g, kernel_t, boundary='symm', mode=mode) + signal.convolve2d(I2g, -kernel_t, boundary='symm', mode=mode)\n",
    "    \n",
    "    # Initializing the matrices u and v of the same shape of the image in which the algorithm will put the vertical and horizontal components of the optical flow\n",
    "    u = np.zeros(I1g.shape)\n",
    "    v = np.zeros(I1g.shape)\n",
    "    # within window window_size * window_size\n",
    "    \n",
    "    \n",
    "    for i in range(w, I1g.shape[0] - w):\n",
    "        for j in range(w, I1g.shape[1] - w):\n",
    "            \n",
    "            # For every pixel in the image we take the derivatives in its neighbourhood \n",
    "            # Initializes the variables Ix, Iy, and It by flattening the spatio-temporal derivatives over the window \"w\"\n",
    "            Ix = fx[i-w:i+w+1, j-w:j+w+1].flatten()\n",
    "            Iy = fy[i-w:i+w+1, j-w:j+w+1].flatten()\n",
    "            It = np.array(ft[i-w:i+w+1, j-w:j+w+1].flatten())\n",
    "            \n",
    "            # Build the matrix A and the vector b to resolve the linear system Au=b\n",
    "            A = np.transpose(np.array([Ix, Iy]))\n",
    "            b = -It\n",
    "            \n",
    "            # compute the smallest eigenvalue of the autocorrelation matrix.\n",
    "            # The eigenvalues of A^T A are related to the gradient of the image and are used to determine if the optical flow calculation is reliable. \n",
    "            # If the minimum eigenvalue is greater than or equal to a threshold \"tau\", then the calculation is considered reliable, \n",
    "            # and the optical flow is calculated. Otherwise, the optical flow is set to zero.\n",
    "            if np.min(abs(np.linalg.eigvals(np.matmul(A.T, A)))) >= tau: \n",
    "                \n",
    "                # Solve the linear system with the pseudo-inverse.\n",
    "                # It could happen that the resulting equations are overdetermined, meaning that there are more equations than unknowns. For such a system the \n",
    "                # matrix inverse method will not work because the A matrix is not square.\n",
    "                # In order to solve the overdetermined system of equations, the Lucas-Kanade algorithm uses the pseudo inverse of the coefficient matrix.\n",
    "                nu = np.matmul(np.linalg.pinv(A), b) \n",
    "                u[i,j] = nu[0] # adding the horizontal component of the optical flow\n",
    "                v[i,j] = nu[1] # adding the vertical component of the optical flow\n",
    "      \n",
    "    \n",
    "    # Return thhe velocity vector of the tracked feature.\n",
    "    # Returns the horizontal and vertical components of the optical flow u and v\n",
    "    return (u,v) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lucas Kanade Algorithm \n",
    "This algorithm is a widely used in computer vision for estimating the optical flow of an image. Optical flow is the apparent motion of objects in an image so it is the answer to the problem of estimating the apparent motion of the brightness pattern of the image.\n",
    "\n",
    "The Lucas-Kanade algorithm assumes that the optical flow is locally constant, so it assumes that the motion between two nearby points in an image is similar. Following the notation of the slides we can say that u is constant in a small neighbourhood of a point.\n",
    "\n",
    "The algorithm works by taking a small window around a pixel in the first image, and searching for a corresponding window in the second image that is most similar to the first one. The displacement between the two is assumed to be the optical flow. The optical flow minimizes the sum-squared error of the brightness constancy equations for each pixel in a window.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Call the previously defined method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "[u,v] = Lucas_Kanade(img1, img2, 7, 0.001)\n",
    "print(\"Elapsed time is %d\"%(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the results of the flow field. We may try the quiver function first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))\n",
    "print(u.shape)\n",
    "print(v.shape)\n",
    "xaxis = list(np.arange(img1.shape[0]))\n",
    "yaxis = list(np.arange(img1.shape[1]))\n",
    "#plt.xlim(0, 352)\n",
    "#plt.ylim(240,0)\n",
    "plt.quiver(u,v)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.quiver??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may also visualize the flow field using a color-coding algorithm ( See https://github.com/tomrunia/OpticalFlow_Visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow = np.stack([u,v], axis=2)\n",
    "flow_color = flow_to_color(flow, convert_to_bgr=False)\n",
    "plt.imshow(flow_color)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   Analysis:\n",
    "\n",
    "- Go back to the function Lucas_Kanade and a comment to explain each line of code  \n",
    "- In particular, can you explain this? <tt> np.min(abs(np.linalg.eigvals(np.matmul(A.T, A)))) >= tau: </tt>\n",
    "**I commented out all the function line by line in the code cell**\n",
    "\n",
    "### Experiments:\n",
    "- Try different window size and thresholds tau \n",
    "- Try different frames (also introducing some temporal gap between them)  \n",
    "- Try both sphere and tennis datasets\n",
    "- What do you observe ? Do you see any specific limits in the very simple LK method?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different thresholds tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tau values: \" + str(np.logspace(-6, -1, num = 6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('Data/sphere/sphere.12.ppm',cv2.IMREAD_GRAYSCALE)\n",
    "img2 = cv2.imread('Data/sphere/sphere.13.ppm',cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(18, 8))\n",
    "\n",
    "for ax, tau in zip(axs.flatten(), np.logspace(-6, -1, num = 6)):\n",
    "    [u,v] = Lucas_Kanade(img1, img2, 7, tau)\n",
    "    ax.set_title(\"Tau: {}\".format(tau))\n",
    "    ax.imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))\n",
    "    ax.quiver(u, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the flow field using a color-coding algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('Data/sphere/sphere.12.ppm',cv2.IMREAD_GRAYSCALE)\n",
    "img2 = cv2.imread('Data/sphere/sphere.13.ppm',cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(18, 8))\n",
    "\n",
    "for ax, tau in zip(axs.flatten(), np.logspace(-6, -1, num = 6)):\n",
    "    \n",
    "    [u,v] = Lucas_Kanade(img1, img2, 7, tau)\n",
    "    ax.set_title(\"Tau: {}\".format(tau))\n",
    "    flow = np.stack([u,v],axis=2)\n",
    "    flow_color = flow_to_color(flow, convert_to_bgr=False)\n",
    "    ax.imshow(flow_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations about tau:** \n",
    "\n",
    "I tried to visualize the flow field for different values of tau. \n",
    "- If **tau is small** we have a bigger number of points in which the optical flow is computed, this result in a more detailed flow field that is better able to capture fine-scale variations in the image. However, this can also make the flow filed more susceptible to noise.\n",
    "- If **tau is big** we have a smaller number of points in which the optical flow is computed, this result in a smoother and less detailed flow field. I think that having a big value for tau can be useful when dealing with noisy images because we can prevent \"overfitting\" to the noise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different window size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Window values: \" + str(np.round(np.linspace(1, 25, num=8))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('Data/sphere/sphere.12.ppm',cv2.IMREAD_GRAYSCALE)\n",
    "img2 = cv2.imread('Data/sphere/sphere.13.ppm',cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "fig, axs = plt.subplots(2, 4, figsize=(18, 8))\n",
    "\n",
    "for ax, w in zip(axs.flatten(), np.round(np.linspace(1, 25, num=8))):\n",
    "    \n",
    "    [u,v] = Lucas_Kanade(img1, img2, w, 1e-5)\n",
    "    ax.set_title(\"Window size: {}\".format(w))\n",
    "    flow = np.stack([u,v],axis=2)\n",
    "    flow_color = flow_to_color(flow, convert_to_bgr=False)\n",
    "    ax.imshow(flow_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations about the window size:**\n",
    "\n",
    "The window size determines the size of the neighborhood around each pixel that is used to estimate the optical flow. The given window size was 7, I tried both to increase it to 11 and to decrease it to 5.\n",
    "- If the **window size is bigger** we will get as result a more global estimate of the optical flow because the algorithm will consider a larger neighborhood around each pixel. I think that increasing the window size can be useful if we are dealing with large-scale motion but if we're dealing with fine-scale motion it may make the algorithm less sensitive.\n",
    "- If the **window size is smaller** we will get as result a more global estimate of the optical flow because the algorithm will consider a smaller neighborhood around each pixel. I think that decresing the window size can be useful if we are dealing with fine-scale motion, but it may also make the algorithm more susceptible to noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different frames (introducing temporal gap between them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('Data/sphere/sphere.1.ppm', cv2.IMREAD_GRAYSCALE)\n",
    "img2 = cv2.imread('Data/sphere/sphere.15.ppm', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "start = time.time()\n",
    "[u,v] = Lucas_Kanade(img1, img2, 7, 0.001)\n",
    "print(\"Elapsed time is %d\"%(time.time() - start))\n",
    "\n",
    "fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize=(8, 6))\n",
    "ax[0].imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))\n",
    "ax[0].quiver(u,v)\n",
    "\n",
    "flow = np.stack([u,v], axis=2)\n",
    "flow_color = flow_to_color(flow, convert_to_bgr=False)\n",
    "ax[1].imshow(flow_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations about different frames with temporal gap:**\n",
    "If we compare two frames with some temporal gap between them (frames that are not consecutive in time), the resulting optical flow field represents the average motion of the objects in the scene over the time interval between the frames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tennis Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('Data/stennis/stennis_001.ppm', cv2.IMREAD_GRAYSCALE)\n",
    "img2 = cv2.imread('Data/stennis/stennis_020.ppm', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "[u,v] = Lucas_Kanade(img1, img2, 7, 0.001)\n",
    "print(\"Elapsed time is %d\"%(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))\n",
    "print(u.shape)\n",
    "print(v.shape)\n",
    "xaxis = list(np.arange(img1.shape[0]))\n",
    "yaxis = list(np.arange(img1.shape[1]))\n",
    "#plt.xlim(0, 352)\n",
    "#plt.ylim(240,0)\n",
    "plt.quiver(u,v)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow = np.stack([u,v], axis=2)\n",
    "flow_color = flow_to_color(flow, convert_to_bgr=False)\n",
    "plt.imshow(flow_color)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations about the Tennis Dataset:**\n",
    "\n",
    "The algorithm manage to detect the movement of the tennis ball. But it seems strange to me that in the tennis ball there are so many arrows pointing downwards since the ball is moving upwards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional Part2 - Pyramidal LK\n",
    "<i>We did not cover the Pyramidal extension during the OF class; this part should be considered as additional and optional material. </i>\n",
    "<br>\n",
    "Now let's take a look at the implementation provided in OpenCV of a pyramid Lucas-Kanade Sparse optical flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm evaluates optical flow on sparse points (corners) in order to avoid the ill-posed inversion of A'A.\n",
    "Additionally, Optical flow is calculated and combined on different scales to handle large-displacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1= cv2.imread('Data/sphere/sphere.12.ppm', cv2.IMREAD_GRAYSCALE)\n",
    "img2= cv2.imread('Data/sphere/sphere.13.ppm', cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters of the corner detection procedure\n",
    "feature_params = dict( maxCorners = 100,\n",
    "                       qualityLevel = 0.1,\n",
    "                       minDistance = 7,\n",
    "                       blockSize = 7 )\n",
    "\n",
    "# Parameters for lucas kanade optical flow\n",
    "lk_params = dict( winSize  = (15,15),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Call the function that detects the key-points (Shi-Tomasi corners) from the first frame \n",
    "2- Call LK Flow algorithm which returns the positions of these key points in the second frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = cv2.goodFeaturesToTrack(img1, mask = None, **feature_params)\n",
    "p1, st, err = cv2.calcOpticalFlowPyrLK(img1, img2, p0, None, **lk_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw vectors to connect points from the first frame and the second frame to visualize the motion vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_new = p1[st==1]\n",
    "good_old = p0[st==1]\n",
    "mask = np.zeros_like(img1)\n",
    "print(good_old.shape)\n",
    "for i,(new,old) in enumerate(zip(p1,p0)):\n",
    "    a,b = np.int32(new.ravel())\n",
    "    c,d = np.int32(old.ravel())\n",
    "    mask = cv2.line(mask, (a,b),(c,d), [255,255,0], 2)\n",
    "img2 = cv2.add(img2,mask)\n",
    "plt.imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tennis Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('Data/stennis/stennis_001.ppm', cv2.IMREAD_GRAYSCALE)\n",
    "img2 = cv2.imread('Data/stennis/stennis_020.ppm', cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters of the corner detection procedure\n",
    "feature_params = dict( maxCorners = 100,\n",
    "                       qualityLevel = 0.1,\n",
    "                       minDistance = 7,\n",
    "                       blockSize = 7 )\n",
    "\n",
    "# Parameters for lucas kanade optical flow\n",
    "lk_params = dict( winSize  = (15,15),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = cv2.goodFeaturesToTrack(img1, mask = None, **feature_params)\n",
    "p1, st, err = cv2.calcOpticalFlowPyrLK(img1, img2, p0, None, **lk_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_new = p1[st==1]\n",
    "good_old = p0[st==1]\n",
    "mask = np.zeros_like(img1)\n",
    "print(good_old.shape)\n",
    "for i,(new,old) in enumerate(zip(p1,p0)):\n",
    "    a,b = np.int32(new.ravel())\n",
    "    c,d = np.int32(old.ravel())\n",
    "    mask = cv2.line(mask, (a,b),(c,d), [255,255,0], 2)\n",
    "img2 = cv2.add(img2,mask)\n",
    "plt.imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
