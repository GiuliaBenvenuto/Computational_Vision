{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6eb6b56-c6c0-49a7-a722-805b6c200bda",
   "metadata": {},
   "source": [
    "# Image Alignment - CV Project \n",
    "## Giulia Benvenuto - 4678610\n",
    "- The detailed description of the entire notebook is in the report in the .zip file. \n",
    "- I cleared both the output cells in the notebook and the output files from the \"Outputs\" folder in order to reduce the size of the .zip file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17b015f-6790-422d-8727-acb09e249baf",
   "metadata": {},
   "source": [
    "## Image Alignment\n",
    "(Detailed description in the Sections 1 and 2 of the Report)\n",
    "\n",
    "This project is about Image alignment, also known as image registration, which is a computer vision technique aimed (as the name suggests) to aligning two or more images so that corresponding points or features in the images are spatially matched.\n",
    "\n",
    "## Image Alignment Pipeline\n",
    "(Detailed description in the Section 2 of the Report)\n",
    "1. Features detection + Features description\n",
    "2. Feature matching\n",
    "3. Find the homography matrix\n",
    "4. Warp perspective\n",
    "\n",
    "Here I decided to:\n",
    "- Use SIFT to localize and describe the keypoints because this algorithm is consideres to be very robust even if its computational time, compared to other algorithms, could be longer.\n",
    "- Use a Brute Force matcher to perform feature matching, because it exhaustively searches for the best matches and it guarantees accurate results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f5cb87-d097-449c-8b88-1578720ce149",
   "metadata": {},
   "source": [
    "## Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb8ac59-9aae-42f2-b77c-0d3cea8bdbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fb62c2-4b17-4601-b1a7-0726328f9d90",
   "metadata": {},
   "source": [
    "## Utility functions\n",
    "(Detailed description in the Section 7 of the Report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4544502f-69fd-42c3-baec-7b6912ad949c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2 (img1, img2, title1, title2):\n",
    "    fig = plt.figure(figsize=(30, 70))\n",
    "    fig.add_subplot(1,2,1)\n",
    "    plt.title(title1)\n",
    "    plt.imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))\n",
    "    fig.add_subplot(1,2,2)\n",
    "    plt.title(title2)\n",
    "    plt.imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b12b5b-6e4a-4105-957c-66ef007e1ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_3 (img1, img2, img3, title1, title2, title3):\n",
    "    fig = plt.figure(figsize=(30, 70)) \n",
    "    fig.add_subplot(1,3,1)\n",
    "    plt.title(title1)\n",
    "    plt.imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))\n",
    "    fig.add_subplot(1,3,2)\n",
    "    plt.title(title2)\n",
    "    plt.imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))\n",
    "    fig.add_subplot(1,3,3)\n",
    "    plt.title(title3)\n",
    "    plt.imshow(cv2.cvtColor(img3, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c5897b-8b03-4989-96aa-28710fc895e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureMatching(des_1, des_2, gl, g):\n",
    "    # Matching\n",
    "    bf = cv2.BFMatcher()\n",
    "    matches = bf.knnMatch(des_1, des_2, k=2)\n",
    "    \n",
    "    n_of_matches = len(matches)\n",
    "    print(\"Total number of matches:\", n_of_matches)\n",
    "    \n",
    "    # Apply ratio test\n",
    "    for m,n in matches:\n",
    "        if m.distance < 0.5 * n.distance:\n",
    "            gl.append([m])\n",
    "            g.append(m)\n",
    "    \n",
    "    print(\"Number of good matches:\", len(good))\n",
    "    n_of_good_matches  = len(good)\n",
    "    \n",
    "    return good_list, good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4700c770-53e9-438f-b388-48a0269b88c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findHomography(n_g_matches, g, kp_1, kp_2):\n",
    "    MIN_MATCH_COUNT = 10\n",
    "    \n",
    "    if n_g_matches > MIN_MATCH_COUNT:\n",
    "        src_pts = np.float32([ kp_1[m.queryIdx].pt for m in g ]).reshape(-1,1,2)\n",
    "        dst_pts = np.float32([ kp_2[m.trainIdx].pt for m in g ]).reshape(-1,1,2)\n",
    "    \n",
    "    homo, mask = cv2.findHomography(dst_pts, src_pts, cv2.RANSAC, 5.0)\n",
    "    print(\"Homography matrix:\\n\", homo)\n",
    "    return homo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13687c5-8b91-4a25-9459-9d57e7592a74",
   "metadata": {},
   "source": [
    "## Poster, Test 1 - 2D rotation of 90 degrees - SUCCESS\n",
    "(Detailed description in the Section 3.1 of the Report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe94067-d21a-47fd-a7cc-664b32f5627f",
   "metadata": {},
   "source": [
    "### Read the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235fce86-10c9-4777-a63d-0e1dbfe6a79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference image:\n",
    "img_poster = cv2.imread('Photos/Poster/img_1.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3ae342-cee5-4662-99ec-ad38025640a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_test1 = cv2.imread('Photos/Poster/img_2.jpeg')\n",
    "\n",
    "# Convert the images to gray scale:\n",
    "img_poster = cv2.cvtColor(img_poster, cv2.COLOR_BGR2GRAY)\n",
    "img_test1 = cv2.cvtColor(img_test1, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Show the images\n",
    "plot_2(img_poster, img_test1, \"Poster\", \"Test image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81004ecd-8132-4b5d-b2d8-c79a9f664c03",
   "metadata": {},
   "source": [
    "### Localization and Description of Keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d83c2c-f64e-48fc-bfe9-9dfdca7dbf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate SIFT detector:\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "# Find the keypoints and descriptors with SIFT:\n",
    "kp1, des1 = sift.detectAndCompute(img_poster, None)\n",
    "kp2, des2 = sift.detectAndCompute(img_test1, None)\n",
    "\n",
    "print(\"Number of keypoints poster image:\", len(kp1))\n",
    "print(\"Number of keypoints test image:\", len(kp2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dde83c-9bbc-437a-a984-e3b8225be401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the keypoints on the poster image:\n",
    "img_sift_poster = None\n",
    "img_sift_poster = cv2.drawKeypoints(img_poster, kp1, img_sift_poster, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "cv2.imwrite('Outputs/Outputs_poster/sift_poster.jpg', img_sift_poster)\n",
    "\n",
    "# Draw the keypoints on the test image:\n",
    "img_sift_test1 = None\n",
    "img_sift_test1 = cv2.drawKeypoints(img_test1, kp2, img_sift_test1, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "cv2.imwrite('Outputs/Outputs_poster/sift_test1.jpg', img_sift_test1)\n",
    "\n",
    "# Show the result of keypoint detection:\n",
    "plot_2(img_sift_poster, img_sift_test1, \"Poster keypoints\", \"Test image keypoints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344357a8-1cc8-4cf8-9f91-5a0929412952",
   "metadata": {},
   "source": [
    "### Fetature Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17174fb-4da4-4b5c-9f4f-2d4ba4b6c3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_list = []\n",
    "good = []\n",
    "good_list, good = featureMatching(des1, des2, good_list, good)\n",
    "\n",
    "n_of_good_matches  = len(good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dfb7bb-f6ad-48e8-a2ea-f8c1cbcfb0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_match_test1 = None\n",
    "img_match_test1 = cv2.drawMatchesKnn(img_poster, kp1, img_test1, kp2, good_list, img_match_test1, flags=2)\n",
    "\n",
    "plt.figure(figsize = (50, 100))\n",
    "plt.title(\"Matches\")\n",
    "plt.imshow(cv2.cvtColor(img_match_test1, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b6cd97-23e6-4350-aa6e-6c4069c97ea7",
   "metadata": {},
   "source": [
    "### Find Homography "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cda504-6a0f-49d6-b071-097f16d3e61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "homography = findHomography(n_of_good_matches, good, kp1, kp2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e91721-a2c5-4926-9374-5e5f379385f6",
   "metadata": {},
   "source": [
    "### Warp Perspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b91e50-3866-4111-934c-69c33b6e1d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_img = cv2.warpPerspective(img_test1, homography, (img_poster.shape[1], img_poster.shape[0]))\n",
    "cv2.imwrite('Outputs/Outputs_poster/aligned_img_test1.jpg', aligned_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bc0f24-34cc-4796-b9b4-430151cda494",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec35031a-5a4e-45bc-9442-e62e1f435108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the result\n",
    "plot_3(img_poster, img_test1, aligned_img, \"Poster\", \"Test image\", \"Aligned test image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2149fab-c64d-42b8-a085-011f4caebba5",
   "metadata": {},
   "source": [
    "## Poster, Test 2 - 3D rotation - SUCCESS\n",
    "(Detailed description in the Section 3.2 of the Report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671a4321-6afd-4a5c-a483-592e8acd37d7",
   "metadata": {},
   "source": [
    "### Read the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373e7533-4926-4575-85a6-3aa0679ea566",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_poster = cv2.imread('Photos/Poster/img_1.jpeg')\n",
    "img_test2 = cv2.imread('Photos/Poster/img_4.jpeg')\n",
    "\n",
    "# Convert the images to gray scale:\n",
    "img_poster = cv2.cvtColor(img_poster, cv2.COLOR_BGR2GRAY)\n",
    "img_test2 = cv2.cvtColor(img_test2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Show the images\n",
    "plot_2(img_poster, img_test2, \"Poster\", \"Test image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a8c3d7-b0e4-4276-8f2f-761a2f73c41d",
   "metadata": {},
   "source": [
    "### Localization and Description of Keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f98f706-30e8-4206-a478-83e29aafe9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate SIFT detector:\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "# Find the keypoints and descriptors with SIFT:\n",
    "kp1, des1 = sift.detectAndCompute(img_poster, None)\n",
    "kp2, des2 = sift.detectAndCompute(img_test2, None)\n",
    "\n",
    "print(\"Number of keypoints poster image:\", len(kp1))\n",
    "print(\"Number of keypoints test image:\", len(kp2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d637eec6-e6d5-4da3-ab2b-a489f406190f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Draw the keypoints on the poster image:\n",
    "img_sift_poster = None\n",
    "img_sift_poster = cv2.drawKeypoints(img_poster, kp1, img_sift_poster, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "cv2.imwrite('Outputs/Outputs_poster/sift_poster.jpg', img_sift_poster)\n",
    "\n",
    "# Draw the keypoints on the test image:\n",
    "img_sift_test2 = None\n",
    "img_sift_test2 = cv2.drawKeypoints(img_test2, kp2, img_sift_test2, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "cv2.imwrite('Outputs/Outputs_poster/sift_test2.jpg', img_sift_test2)\n",
    "\n",
    "# Show the result of keypoint detection:\n",
    "plot_2(img_sift_poster, img_sift_test2, \"Poster keypoints\", \"Test image keypoints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0db421-89d2-48d6-aac2-5b5872ce9281",
   "metadata": {},
   "source": [
    "### Fetature Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26e8bc3-e316-405b-b9a9-e852aec40702",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_list = []\n",
    "good = []\n",
    "good_list, good = featureMatching(des1, des2, good_list, good)\n",
    "\n",
    "n_of_good_matches  = len(good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510bc714-5eed-4090-b298-a5ffa4d750ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_match_test2 = None\n",
    "img_match_test2 = cv2.drawMatchesKnn(img_poster, kp1, img_test2, kp2, good_list, img_match_test2, flags=2)\n",
    "plt.figure(figsize = (50, 100))\n",
    "plt.title(\"Matches\")\n",
    "plt.imshow(cv2.cvtColor(img_match_test2, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217d13f2-6729-4c25-928a-c78524b25daf",
   "metadata": {},
   "source": [
    "### Find Homography "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9825233-187e-4e11-a7ab-890174456fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "homography = findHomography(n_of_good_matches, good, kp1, kp2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cbaf8d-9c40-4eab-975f-c297d0c1e853",
   "metadata": {},
   "source": [
    "### Warp Perspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbfacf8-afc1-4d5b-ae33-0bc760b890a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_img = cv2.warpPerspective(img_test2, homography, (img_poster.shape[1], img_poster.shape[0]))\n",
    "cv2.imwrite('Outputs/Outputs_poster/aligned_img_test2.jpg', aligned_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02578c6-ee41-4b7d-b455-2c1bb55f090c",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7d117d-6088-42b1-859b-756a2ea890d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the result\n",
    "plot_3(img_poster, img_test2, aligned_img, \"Poster\", \"Test image\", \"Aligned test image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbd3e0d-18f4-40b6-b403-09e95f22ec8d",
   "metadata": {},
   "source": [
    "## Drawing 1, Test 1 - 2D rotation of 45 degrees - SUCCESS\n",
    "(Detailed description in the Section 3.3 of the Report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce1dbdb-c33c-4cc2-904d-678f42e6968a",
   "metadata": {},
   "source": [
    "### Read the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5004a2d5-1e7d-437c-b236-8bca16c4dfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_draw1 = cv2.imread('Photos/Draw1/img1.jpg')\n",
    "img_draw1_test1 = cv2.imread('Photos/Draw1/img5.jpg')\n",
    "\n",
    "# Convert the images to gray scale:\n",
    "img_draw1 = cv2.cvtColor(img_draw1, cv2.COLOR_BGR2GRAY)\n",
    "img_draw1_test1 = cv2.cvtColor(img_draw1_test1, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Show the images\n",
    "plot_2(img_draw1, img_draw1_test1, \"Drawing 1\", \"Test image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2078c5-9169-4c68-be12-1bb945a59841",
   "metadata": {},
   "source": [
    "### Localization and Description of Keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a05817-344a-44c0-87cf-4afc24515449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate SIFT detector:\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "# Find the keypoints and descriptors with SIFT:\n",
    "kp1, des1 = sift.detectAndCompute(img_draw1, None)\n",
    "kp2, des2 = sift.detectAndCompute(img_draw1_test1, None)\n",
    "\n",
    "print(\"Number of keypoints poster image:\", len(kp1))\n",
    "print(\"Number of keypoints test image:\", len(kp2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf0abf5-a5d7-46f1-92c6-a83c4fea6739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the keypoints on the poster image:\n",
    "img_sift_draw1 = None\n",
    "img_sift_draw1 = cv2.drawKeypoints(img_draw1, kp1, img_sift_draw1, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "cv2.imwrite('Outputs/Outputs_draw1/sift_draw1.jpg', img_sift_draw1)\n",
    "\n",
    "# Draw the keypoints on the test image:\n",
    "img_sift_draw1_test1 = None\n",
    "img_sift_draw1_test1 = cv2.drawKeypoints(img_draw1_test1, kp2, img_sift_draw1_test1, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "cv2.imwrite('Outputs/Outputs_draw1/sift_draw1_test1.jpg', img_sift_draw1_test1)\n",
    "\n",
    "# Show the result of keypoint detection:\n",
    "plot_2(img_sift_draw1, img_sift_draw1_test1, \"Drawing 1 keypoints\", \"Test image keypoints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496b9bd2-7549-4578-930a-9625b96f84c5",
   "metadata": {},
   "source": [
    "### Fetature Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090a0f51-6ac4-4adb-ba18-b9c79b6b54e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_list = []\n",
    "good = []\n",
    "good_list, good = featureMatching(des1, des2, good_list, good)\n",
    "\n",
    "n_of_good_matches  = len(good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043dcfb8-20ea-4ec9-ac70-cb62c2279ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_match_draw1_test1 = None\n",
    "img_match_draw1_test1 = cv2.drawMatchesKnn(img_draw1, kp1, img_draw1_test1, kp2, good_list, img_match_draw1_test1, flags=2)\n",
    "plt.figure(figsize = (50, 100))\n",
    "plt.title(\"Matches\")\n",
    "plt.imshow(cv2.cvtColor(img_match_draw1_test1, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a74c38f-4b2e-4781-b7b4-8cfa71a472e6",
   "metadata": {},
   "source": [
    "### Find Homography "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7031ac83-00bf-4adb-8100-4db9c892c4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "homography = findHomography(n_of_good_matches, good, kp1, kp2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19466542-efea-4e16-bb21-270cfe64f806",
   "metadata": {},
   "source": [
    "### Warp Perspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13913ab9-c242-46ad-b785-9c92d13a55da",
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_img = cv2.warpPerspective(img_draw1_test1, homography, (img_draw1.shape[1], img_draw1.shape[0]))\n",
    "cv2.imwrite('Outputs/Outputs_draw1/aligned_img_test1.jpg', aligned_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a67de41-a23f-48b3-b4a5-62a7d55e7f07",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3857909-bcae-4b6d-b062-b11b9d057ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the result\n",
    "plot_3(img_draw1, img_draw1_test1, aligned_img, \"Drawing 1\", \"Test image\", \"Aligned test image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5e55ff-d03b-46c0-9bc1-63b2261a1d4d",
   "metadata": {},
   "source": [
    "## Drawing 1, Test 2 - 3D rotation - FAIL\n",
    "(Detailed description in the Section 3.4 of the Report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58903e8-b097-41a9-bc26-d31550046e48",
   "metadata": {},
   "source": [
    "### Read the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02503966-3b19-4ba5-951c-8560fa24906c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_draw1 = cv2.imread('Photos/Draw1/img1.jpg')\n",
    "img_draw1_test2 = cv2.imread('Photos/Draw1/img6.jpg')\n",
    "\n",
    "# Convert the images to gray scale:\n",
    "img_draw1 = cv2.cvtColor(img_draw1, cv2.COLOR_BGR2GRAY)\n",
    "img_draw1_test2 = cv2.cvtColor(img_draw1_test2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Show the images\n",
    "plot_2(img_draw1, img_draw1_test2, \"Drawing 1\", \"Test image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4342bb70-9044-4251-90cb-2be1ee9cd34b",
   "metadata": {},
   "source": [
    "### Localization and Description of Keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cce971-ba1e-4a20-8adb-e782d6a1bdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate SIFT detector:\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "# Find the keypoints and descriptors with SIFT:\n",
    "kp1, des1 = sift.detectAndCompute(img_draw1, None)\n",
    "kp2, des2 = sift.detectAndCompute(img_draw1_test2, None)\n",
    "\n",
    "print(\"Number of keypoints poster image:\", len(kp1))\n",
    "print(\"Number of keypoints test image:\", len(kp2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fb4678-4da3-4454-9e57-dce242fe1e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the keypoints on the poster image:\n",
    "img_sift_draw1 = None\n",
    "img_sift_draw1 = cv2.drawKeypoints(img_draw1, kp1, img_sift_draw1, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "cv2.imwrite('Outputs/Outputs_draw1/sift_draw1.jpg', img_sift_draw1)\n",
    "\n",
    "# Draw the keypoints on the test image:\n",
    "img_sift_draw1_test2 = None\n",
    "img_sift_draw1_test2 = cv2.drawKeypoints(img_draw1_test2, kp2, img_sift_draw1_test2, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "cv2.imwrite('Outputs/Outputs_draw1/sift_draw1_test2.jpg', img_sift_draw1_test2)\n",
    "\n",
    "# Show the result of keypoint detection:\n",
    "plot_2(img_sift_draw1, img_sift_draw1_test2, \"Drawing 1 keypoints\", \"Test image keypoints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042fba4c-3600-41fa-99a8-25adebd112d4",
   "metadata": {},
   "source": [
    "### Fetature Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495f411c-35ab-451b-bdac-cdef00d72972",
   "metadata": {},
   "source": [
    "Need to set to 0.75 otherwise we don't have enough good features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31c1b85-adf4-4f3e-a993-5a092c70bc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matching\n",
    "bf = cv2.BFMatcher()\n",
    "matches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "n_of_matches = len(matches)\n",
    "print(\"Total number of matches:\", n_of_matches)\n",
    "\n",
    "# Apply ratio test\n",
    "good_list = []\n",
    "good = []\n",
    "for m,n in matches:\n",
    "    if m.distance < 0.75 * n.distance:\n",
    "        good_list.append([m])\n",
    "        good.append(m)\n",
    "\n",
    "print(\"Number of good matches:\", len(good))\n",
    "n_of_good_matches  = len(good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ceb7474-67c8-4ee1-bad9-5ccf1a41e349",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_match_draw1_test2 = None\n",
    "img_match_draw1_test2 = cv2.drawMatchesKnn(img_draw1, kp1, img_draw1_test2, kp2, good_list, img_match_draw1_test2, flags=2)\n",
    "plt.figure(figsize = (50, 100))\n",
    "plt.title(\"Matches\")\n",
    "plt.imshow(cv2.cvtColor(img_match_draw1_test2, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf58d9f-27bd-47c4-b478-b6bbba6d4ffd",
   "metadata": {},
   "source": [
    "### Find Homography "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e6cb96-5a5e-422b-8d57-9f5fca14e83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "homography = findHomography(n_of_good_matches, good, kp1, kp2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f868cf73-05d1-4468-807a-6b55a8d1b041",
   "metadata": {},
   "source": [
    "### Warp Perspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6d6734-657e-4aee-a272-aec9a5b22164",
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_img = cv2.warpPerspective(img_draw1_test2, homography, (img_draw1.shape[1], img_draw1.shape[0]))\n",
    "cv2.imwrite('Outputs/Outputs_draw1/aligned_img_test2.jpg', aligned_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51475856-2a68-47ef-9e07-d4c3a798e34e",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecc083d-f62e-4515-b07d-20a8e47edc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the result\n",
    "plot_3(img_draw1, img_draw1_test2, aligned_img, \"Drawing 1\", \"Test image\", \"Aligned test image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75b3c3b-cefe-43e8-b10c-6450b8554ae5",
   "metadata": {},
   "source": [
    "## Drawing 2, Test 1 - 3D rotation - FAIL\n",
    "(Detailed description in the Section 3.5 of the Report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68d2fc7-f877-4882-ad3b-1919d6d38790",
   "metadata": {},
   "source": [
    "### Read the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ff2035-0058-49a2-84fb-b666d7513713",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_draw2 = cv2.imread('Photos/Draw2/img1.jpg')\n",
    "img_draw2_test1 = cv2.imread('Photos/Draw2/img3.jpg')\n",
    "\n",
    "# Convert the images to gray scale:\n",
    "img_draw2 = cv2.cvtColor(img_draw2, cv2.COLOR_BGR2GRAY)\n",
    "img_draw2_test1 = cv2.cvtColor(img_draw2_test1, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Show the images\n",
    "plot_2(img_draw2, img_draw2_test1, \"Drawing 2\", \"Test image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d778310-d8a8-4e74-bb7b-6a7a9e7ebb7e",
   "metadata": {},
   "source": [
    "### Localization and Description of Keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996c91ec-5ba6-419a-9b0d-c322976d12cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate SIFT detector:\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "# Find the keypoints and descriptors with SIFT:\n",
    "kp1, des1 = sift.detectAndCompute(img_draw2, None)\n",
    "kp2, des2 = sift.detectAndCompute(img_draw2_test1, None)\n",
    "\n",
    "print(\"Number of keypoints poster image:\", len(kp1))\n",
    "print(\"Number of keypoints test image:\", len(kp2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7035f565-ae11-4cab-82c5-67bad5a2fa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the keypoints on the poster image:\n",
    "img_sift_draw2 = None\n",
    "img_sift_draw2 = cv2.drawKeypoints(img_draw2, kp1, img_sift_draw2, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "cv2.imwrite('Outputs/Outputs_draw2/sift_draw2.jpg', img_sift_draw2)\n",
    "\n",
    "# Draw the keypoints on the test image:\n",
    "img_sift_draw2_test1 = None\n",
    "img_sift_draw2_test1 = cv2.drawKeypoints(img_draw2_test1, kp2, img_sift_draw2_test1, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "cv2.imwrite('Outputs/Outputs_draw2/sift_draw2_test1.jpg', img_sift_draw2_test1)\n",
    "\n",
    "# Show the result of keypoint detection:\n",
    "plot_2(img_sift_draw2, img_sift_draw2_test1, \"Drawing 2 keypoints\", \"Test image keypoints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e128921c-1d3a-4428-b978-f75d8b012ece",
   "metadata": {},
   "source": [
    "### Fetature Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122f7df3-27be-4168-891b-17d26cbc9471",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_list = []\n",
    "good = []\n",
    "good_list, good = featureMatching(des1, des2, good_list, good)\n",
    "\n",
    "n_of_good_matches  = len(good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6a1dcb-ad8d-422f-b627-f8535416e121",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_match_draw2_test1 = None\n",
    "img_match_draw2_test1 = cv2.drawMatchesKnn(img_draw2, kp1, img_draw2_test1, kp2, good_list, img_match_draw2_test1, flags=2)\n",
    "plt.figure(figsize = (50, 100))\n",
    "plt.title(\"Matches\")\n",
    "plt.imshow(cv2.cvtColor(img_match_draw2_test1, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89be1bb-34b7-43a1-8a06-396e47ae633a",
   "metadata": {},
   "source": [
    "### Find Homography "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf15c90-a6b5-40ce-96e5-b7fd3a3891e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "homography = findHomography(n_of_good_matches, good, kp1, kp2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831a4213-cf97-46a2-bdaa-09aaea982683",
   "metadata": {},
   "source": [
    "### Warp Perspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e057930c-8b73-4de6-b250-2ddaedb5cac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_img = cv2.warpPerspective(img_draw2_test1, homography, (img_draw2.shape[1], img_draw2.shape[0]))\n",
    "cv2.imwrite('Outputs/Outputs_draw2/aligned_img_test1.jpg', aligned_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2afbcc-b5d7-4db5-bb9b-e94b2ed0ba58",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e925954c-8140-42e6-80a2-574df7a2e102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the result\n",
    "plot_3(img_draw2, img_draw2_test1, aligned_img, \"Drawing 2\", \"Test image\", \"Aligned test image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb4f8bd-e79c-406d-8dfc-e25050ead812",
   "metadata": {},
   "source": [
    "## 3D Object - Rubik's Cube - FAIL\n",
    "(Detailed description in the Section 3.6 of the Report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cf02f2-30fd-45dd-ab50-09e4e9c0cf31",
   "metadata": {},
   "source": [
    "### Read the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ada0c81-b424-4b02-8ea0-3b574b49beeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rubik = cv2.imread('Photos/3D_objects/rubik_6.jpeg')\n",
    "rubik_test = cv2.imread('Photos/3D_objects/rubik_4.jpeg')\n",
    "\n",
    "# Convert the images to gray scale:\n",
    "rubik = cv2.cvtColor(rubik, cv2.COLOR_BGR2GRAY)\n",
    "rubik_test = cv2.cvtColor(rubik_test, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Show the images\n",
    "plot_2(rubik, rubik_test, \"Rubik's Cube\", \"Test image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80be932d-0d5b-44bf-828c-469e02f7dcae",
   "metadata": {},
   "source": [
    "### Localization and Description of Keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415e4226-5e55-4656-b112-57e73ac4f683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate SIFT detector:\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "# Find the keypoints and descriptors with SIFT:\n",
    "kp1, des1 = sift.detectAndCompute(rubik, None)\n",
    "kp2, des2 = sift.detectAndCompute(rubik_test, None)\n",
    "\n",
    "print(\"Number of keypoints poster image:\", len(kp1))\n",
    "print(\"Number of keypoints test image:\", len(kp2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c245d00d-139a-4af6-bca2-f6ba3244b6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the keypoints on the poster image:\n",
    "rubik_sift = None\n",
    "rubik_sift = cv2.drawKeypoints(rubik, kp1, rubik_sift, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "cv2.imwrite('Outputs/Outputs_rubik/rubik_sift.jpg', rubik_sift)\n",
    "\n",
    "# Draw the keypoints on the test image:\n",
    "rubik_sift_test = None\n",
    "rubik_sift_test = cv2.drawKeypoints(rubik_test, kp2, rubik_sift_test, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "cv2.imwrite('Outputs/Outputs_rubik/rubik_sift_test.jpg', rubik_sift_test)\n",
    "\n",
    "# Show the result of keypoint detection:\n",
    "plot_2(rubik_sift, rubik_sift_test, \"Rubik keypoints\", \"Test image keypoints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d42d628-f949-4daa-8a16-dd90b4d357a1",
   "metadata": {},
   "source": [
    "### Feature Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c08b7c8-f59d-4921-bcea-c97c1af0bd6f",
   "metadata": {},
   "source": [
    "Need to set to 0.75 otherwise we don't have enough goof features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbe2aff-cb4e-40c6-8c79-70c2ec40f725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matching\n",
    "bf = cv2.BFMatcher()\n",
    "matches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "n_of_matches = len(matches)\n",
    "print(\"Total number of matches:\", n_of_matches)\n",
    "\n",
    "# Apply ratio test\n",
    "good_list = []\n",
    "good = []\n",
    "for m,n in matches:\n",
    "    if m.distance < 0.75 * n.distance:\n",
    "        good_list.append([m])\n",
    "        good.append(m)\n",
    "\n",
    "print(\"Number of good matches:\", len(good))\n",
    "n_of_good_matches  = len(good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927726bc-cf7f-4003-851b-71ac3fd56777",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_rubik = None\n",
    "match_rubik = cv2.drawMatchesKnn(rubik, kp1, rubik_test, kp2, good_list, match_rubik, flags=2)\n",
    "plt.figure(figsize = (50, 100))\n",
    "plt.title(\"Matches\")\n",
    "plt.imshow(cv2.cvtColor(match_rubik, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b46c85-2f31-4324-b9e1-664883970a44",
   "metadata": {},
   "source": [
    "### Find Homography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fb7f16-2512-4847-b16c-d5e6591b6ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "homography = findHomography(n_of_good_matches, good, kp1, kp2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5229e0c6-4fe1-4a12-b815-8958621a1770",
   "metadata": {},
   "source": [
    "### Warp perspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6cf28a-1c51-422c-8bcb-028153115e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_img = cv2.warpPerspective(rubik_test, homography, (rubik.shape[1], rubik.shape[0]))\n",
    "cv2.imwrite('Outputs/Outputs_rubik/aligned_rubik.jpg', aligned_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c925baff-6968-4167-a96b-99b07fda0c20",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e959d1b-38d1-4d37-90ca-1c0c4a9b6873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the result\n",
    "plot_3(rubik, rubik_test, aligned_img, \"Rubik\", \"Test image\", \"Aligned test image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d20650-bfa7-4594-befd-7351fec811c4",
   "metadata": {},
   "source": [
    "## 3D Object - Canteen - FAIL\n",
    "(Detailed description in the Section 3.7 of the Report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ec43f4-5969-49b4-a313-57991d0cb350",
   "metadata": {},
   "source": [
    "### Read the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6bb454-2bfb-4e74-84cf-3d343bf7985a",
   "metadata": {},
   "outputs": [],
   "source": [
    "canteen = cv2.imread('Photos/3D_objects/canteen_1.jpeg')\n",
    "canteen_test = cv2.imread('Photos/3D_objects/canteen_2.jpeg')\n",
    "\n",
    "# Convert the images to gray scale:\n",
    "canteen = cv2.cvtColor(canteen, cv2.COLOR_BGR2GRAY)\n",
    "canteen_test = cv2.cvtColor(canteen_test, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Show the images\n",
    "plot_2(canteen, canteen_test, \"Canteen\", \"Test image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840545a2-b64e-45a7-bc59-8e25be3bb644",
   "metadata": {},
   "source": [
    "### Localization and Description of Keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3854c3ff-6728-4266-9b2c-85825c00f107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate SIFT detector:\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "# Find the keypoints and descriptors with SIFT:\n",
    "kp1, des1 = sift.detectAndCompute(canteen, None)\n",
    "kp2, des2 = sift.detectAndCompute(canteen_test, None)\n",
    "\n",
    "print(\"Number of keypoints poster image:\", len(kp1))\n",
    "print(\"Number of keypoints test image:\", len(kp2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c0ac65-d0fb-485b-aa15-979f958d7731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the keypoints on the poster image:\n",
    "img_sift_canteen= None\n",
    "img_sift_canteen = cv2.drawKeypoints(canteen, kp1, img_sift_canteen, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "cv2.imwrite('Outputs/Outputs_canteen/sift_canteen.jpg', img_sift_canteen)\n",
    "\n",
    "# Draw the keypoints on the test image:\n",
    "img_sift_test = None\n",
    "img_sift_test = cv2.drawKeypoints(canteen_test, kp2, img_sift_test, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "cv2.imwrite('Outputs/Outputs_canteen/sift_canteen_test.jpg', img_sift_test)\n",
    "\n",
    "# Show the result of keypoint detection:\n",
    "plot_2(img_sift_canteen, img_sift_test, \"Canteen keypoints\", \"Test image keypoints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91a4f53-dfe1-470b-8ebd-e7fca0524024",
   "metadata": {},
   "source": [
    "### Feature Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dae4346-ddad-4a0f-8b1e-ddc42cac1d7c",
   "metadata": {},
   "source": [
    "Need to set to 0.75 otherwise we don't have enough goof features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a816022a-b3ef-4c66-bd3e-4a9fbbcc8412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matching\n",
    "bf = cv2.BFMatcher()\n",
    "matches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "n_of_matches = len(matches)\n",
    "print(\"Total number of matches:\", n_of_matches)\n",
    "\n",
    "# Apply ratio test\n",
    "good_list = []\n",
    "good = []\n",
    "for m,n in matches:\n",
    "    if m.distance < 0.75 * n.distance:\n",
    "        good_list.append([m])\n",
    "        good.append(m)\n",
    "\n",
    "print(\"Number of good matches:\", len(good))\n",
    "n_of_good_matches  = len(good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c8c474-c8d7-4a15-81aa-55e14bce1938",
   "metadata": {},
   "outputs": [],
   "source": [
    "canteen_match = None\n",
    "canteen_match = cv2.drawMatchesKnn(canteen, kp1, canteen_test, kp2, good_list, canteen_match, flags=2)\n",
    "plt.figure(figsize = (50, 100))\n",
    "plt.title(\"Matches\")\n",
    "plt.imshow(cv2.cvtColor(canteen_match, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93fc951-2cfe-4d72-85ee-b244b7df2983",
   "metadata": {},
   "source": [
    "### Find Homography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4546ab0-1c1b-4dfb-b886-70de570c6eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "homography = findHomography(n_of_good_matches, good, kp1, kp2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4116a7f6-a0d6-478f-99fc-03b1083b8dd6",
   "metadata": {},
   "source": [
    "### Warp Perspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa4bf3d-e771-444a-84a4-1ab5b15c77bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_img_canteen = cv2.warpPerspective(canteen_test, homography, (canteen.shape[1], canteen.shape[0]))\n",
    "cv2.imwrite('Outputs/Outputs_canteen/aligned_canteen.jpg', aligned_img_canteen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb9498d-4b15-4be2-a308-4c6a116b323f",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cd51eb-1c09-4b46-aa47-b3b09a7be710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the result\n",
    "plot_3(canteen, canteen_test, aligned_img_canteen, \"Canteen\", \"Test image\", \"Aligned test image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9baaa7e-95c9-4332-8a3d-0bb52a87e880",
   "metadata": {},
   "source": [
    "## Image alignment for form alignment - 3D rotation - SUCCESS\n",
    "(Detailed description in the Section 4.1 of the Report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86869db8-6f5f-45e6-ada2-77184a5f3262",
   "metadata": {},
   "source": [
    "### Read the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93edc07-c3aa-4a47-96a5-186604aeaf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_template = cv2.imread('Photos/Form/form_template.jpg')\n",
    "img_test = cv2.imread('Photos/Form/img12.jpeg')\n",
    "\n",
    "# Convert the images to gray scale:\n",
    "img_template = cv2.cvtColor(img_template, cv2.COLOR_BGR2GRAY)\n",
    "img_test = cv2.cvtColor(img_test, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Show the images\n",
    "plot_2(img_template, img_test, \"Form template\", \"Test image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c34a5f4-8ef7-4cde-adbd-74218f84a320",
   "metadata": {},
   "source": [
    "### Localization and Description of Keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6d1d84-9519-47bc-9f44-d7e10ac5ad09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate SIFT detector:\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "# Find the keypoints and descriptors with SIFT:\n",
    "kp1, des1 = sift.detectAndCompute(img_template, None)\n",
    "kp2, des2 = sift.detectAndCompute(img_test, None)\n",
    "\n",
    "print(\"Number of keypoints poster image:\", len(kp1))\n",
    "print(\"Number of keypoints test image:\", len(kp2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d7866c-acea-482a-b305-780b6c45c111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the keypoints on the poster image:\n",
    "img_sift_template = None\n",
    "img_sift_template = cv2.drawKeypoints(img_template, kp1, img_sift_template, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "cv2.imwrite('Outputs/Outputs_form/sift_form_template.jpg', img_sift_template)\n",
    "\n",
    "# Draw the keypoints on the test image:\n",
    "img_sift_test = None\n",
    "img_sift_test = cv2.drawKeypoints(img_test, kp2, img_sift_test, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "cv2.imwrite('Outputs/Outputs_form/sift_test.jpg', img_sift_test)\n",
    "\n",
    "# Show the result of keypoint detection:\n",
    "plot_2(img_sift_template, img_sift_test, \"Form template keypoints\", \"Test image keypoints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd81df0-2513-4b01-8109-fac78b2f9d87",
   "metadata": {},
   "source": [
    "### Fetature Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5531482f-e8d7-471d-95fe-aafdb19e17b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_list = []\n",
    "good = []\n",
    "good_list, good = featureMatching(des1, des2, good_list, good)\n",
    "\n",
    "n_of_good_matches  = len(good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b7bc7b-227d-44ba-9af7-3232bf1dee73",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_match_form = None\n",
    "img_match_form = cv2.drawMatchesKnn(img_template, kp1, img_test, kp2, good_list, img_match_form, flags=2)\n",
    "plt.figure(figsize = (50, 100))\n",
    "plt.title(\"Matches\")\n",
    "plt.imshow(cv2.cvtColor(img_match_form, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918dd2fc-57f5-4c79-80d8-aea5910bec97",
   "metadata": {},
   "source": [
    "### Find Homography "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c56179-bed3-4d0d-9652-f0f0ed768b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "homography = findHomography(n_of_good_matches, good, kp1, kp2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe3cd25-bc0e-471d-8f61-4b0d60bce6b0",
   "metadata": {},
   "source": [
    "### Warp Perspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f582915f-008c-4104-9ef5-3a19a2d37831",
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_img_form = cv2.warpPerspective(img_test, homography, (img_template.shape[1], img_template.shape[0]))\n",
    "cv2.imwrite('Outputs_form/aligned_img_form.jpg', aligned_img_form)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cea796-eaf9-43a3-b844-ec2d48754b3a",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5285f87-b9eb-42d5-b0d3-0c1d189f9d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the result\n",
    "plot_3(img_template, img_test, aligned_img_form, \"Form template\", \"Test image\", \"Aligned test image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e5f558-e12c-479e-ae9f-9a5b1635d68a",
   "metadata": {},
   "source": [
    "## Image alignment for panorama stitching from scratch\n",
    "(Detailed description in the Section 4.2.1 of the Report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d8ce1f-26a1-4e42-a3ac-42fc4d109e58",
   "metadata": {},
   "source": [
    "### Read the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e87da5d-fe85-4f0e-9b99-458506b3caf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images:\n",
    "left_img = cv2.imread('Photos/Bedroom/try1_4.jpg')\n",
    "right_img = cv2.imread('Photos/Bedroom/try1_5.jpg')\n",
    "\n",
    "# Convert the images to gray scale:\n",
    "left_img = cv2.cvtColor(left_img, cv2.COLOR_BGR2GRAY)\n",
    "right_img = cv2.cvtColor(right_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Show the images\n",
    "plot_2(left_img, right_img, \"Left image\", \"Right image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a39346d-017d-42fb-bcd1-cd7b3056e816",
   "metadata": {},
   "source": [
    "### Localization and Description of Keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426b7e20-4841-4786-bdac-9277607c7533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate SIFT detector:\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "# Find the keypoints and descriptors with SIFT:\n",
    "kp_left, des_left = sift.detectAndCompute(left_img, None)\n",
    "kp_right, des_right = sift.detectAndCompute(right_img, None)\n",
    "\n",
    "print(\"Number of keypoints left image:\", len(kp_left))\n",
    "print(\"Number of keypoints right image:\", len(kp_right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2198b9fb-b15d-4426-8635-88d43140d94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the keypoints on the left image:\n",
    "left_img_sift = None\n",
    "left_img_sift = cv2.drawKeypoints(left_img, kp_left, left_img_sift, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "cv2.imwrite('Outputs/Outputs_stitching/left_img_sift.jpg', left_img_sift)\n",
    "\n",
    "# Draw the keypoints on the right image:\n",
    "right_img_sift = None\n",
    "right_img_sift = cv2.drawKeypoints(right_img, kp_right, right_img_sift, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "cv2.imwrite('Outputs/Outputs_stitching/right_img_sift.jpg', right_img_sift)\n",
    "\n",
    "# Show the result of keypoint detection:\n",
    "plot_2(left_img_sift, right_img_sift, \"Left image keypoints\", \"Right image keypoints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bb8b76-284d-4cd2-a937-ef5a50ba26e7",
   "metadata": {},
   "source": [
    "### Feature Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f28bbf-4145-4975-be7d-25e135629f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_list = []\n",
    "good = []\n",
    "good_list, good = featureMatching(des_left, des_right, good_list, good)\n",
    "\n",
    "n_of_good_matches  = len(good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6061e9a0-d1ee-4af3-9c75-691f0a0688e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_match_bedroom = None\n",
    "img_match_bedroom = cv2.drawMatchesKnn(left_img, kp_left, right_img, kp_right, good_list, img_match_bedroom, flags=2)\n",
    "plt.figure(figsize = (50, 100))\n",
    "plt.title(\"Matches\")\n",
    "plt.imshow(cv2.cvtColor(img_match_bedroom, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ad28de-0846-4347-8c27-f92f527f9067",
   "metadata": {},
   "source": [
    "### Find Homography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cebe91b-bdd5-416f-bbb4-8e2bd123c324",
   "metadata": {},
   "outputs": [],
   "source": [
    "homography = findHomography(n_of_good_matches, good, kp_left, kp_right)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8617b18-ad19-4ad6-8d9b-8c6d10fd2134",
   "metadata": {},
   "source": [
    "### Stitch Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ca0b47-a704-4992-8f9c-3a2104434c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/bakkyn/Image-Alignment-using-OpenCV/blob/main/image_alignment/Image_Alignment.ipynb\n",
    "def stitchImages(img_left, img_right, homography):\n",
    "    \n",
    "    # get height and weight values\n",
    "    rowl, coll = img_left.shape[:2]\n",
    "    rowr, colr = img_right.shape[:2]\n",
    "\n",
    "    # left to right - corner coordinates\n",
    "    left = np.float32([[0,0], [0, rowl],[coll, rowl], [coll, 0]]).reshape(-1, 1,2)\n",
    "    right = np.float32([[0,0], [0,rowr], [colr,rowr], [colr,0]]).reshape(-1,1,2)\n",
    "\n",
    "    # To apply homography we need wrap perspective. Calculate the transformation matrix\n",
    "    right = cv2.perspectiveTransform(right, homography)\n",
    "        \n",
    "    points = np.concatenate((left, right), axis=0)\n",
    "\n",
    "    # get min max coordinates \n",
    "    min_p = points.min(axis=0).ravel() # search for one dim\n",
    "    max_p = points.max(axis=0).ravel()\n",
    "    [minx, miny] = np.int32(min_p - 0.5)\n",
    "    [maxx, maxy] = np.int32(max_p + 0.5)\n",
    "  \n",
    "    block = [-minx, -miny]\n",
    "    hom_translation = np.array([[1, 0, block[0]], [0, 1, block[1]], [0, 0, 1]])\n",
    "\n",
    "    final_img = cv2.warpPerspective(img_right, hom_translation.dot(homography), (maxx-minx, maxy-miny))\n",
    "    final_img[block[1]:rowl+block[1], block[0]:coll+block[0]] = img_left\n",
    "\n",
    "    return final_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d68926-3f34-4bab-87eb-30725a44c68a",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807ee1a6-d54c-41af-ae51-ef8a1ca1929c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = stitchImages(left_img, right_img, homography)\n",
    "\n",
    "plt.title(\"Result image\")\n",
    "plt.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb86268-005c-4a63-beeb-82817d593c2d",
   "metadata": {},
   "source": [
    "## Image alignment for panorama using OpenCV function - 2 Images\n",
    "(Detailed description in the Section 4.2.2 of the Report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef058c3e-6ae8-4cec-aa87-4d101ecf9c80",
   "metadata": {},
   "source": [
    "### Read the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2127c9b8-6ad2-499a-b422-6f01f368b757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images:\n",
    "left_img = cv2.imread('Photos/Bedroom/try1_4.jpg')\n",
    "right_img = cv2.imread('Photos/Bedroom/try1_5.jpg')\n",
    "\n",
    "# Convert the images to gray scale:\n",
    "left_img = cv2.cvtColor(left_img, cv2.COLOR_BGR2GRAY)\n",
    "right_img = cv2.cvtColor(right_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Show the images\n",
    "plot_2(left_img, right_img, \"Left image\", \"Right image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a394af-e4e4-4166-bb0e-7440f79fdb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = [cv2.cvtColor(cv2.imread('Photos/Bedroom/try1_4.jpg'), cv2.COLOR_BGR2RGB), \n",
    "        cv2.cvtColor(cv2.imread('Photos/Bedroom/try1_5.jpg'), cv2.COLOR_BGR2RGB)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37e2955-f6b8-4c55-95d8-4ad546f097ef",
   "metadata": {},
   "source": [
    "### Stitch the images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e531836-2706-48c9-88fc-4d34fa8d82b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stitch_images(images):\n",
    "    # Create a Stitcher object\n",
    "    stitcher = cv2.Stitcher_create(cv2.Stitcher_PANORAMA)\n",
    "    \n",
    "    # Stitch the images together\n",
    "    # output status, result image\n",
    "    _ , result = stitcher.stitch(images)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0763495-4087-485d-bba2-d74a93ae7ee5",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b14e9f8-cea4-4bcc-9ddd-7e830c406bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = stitch_images(imgs)\n",
    "\n",
    "plt.title(\"Result image\")\n",
    "plt.imshow(result)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d09253f-052b-4940-b7ee-b2195259dcdb",
   "metadata": {},
   "source": [
    "## Image alignment for panorama using OpenCV function - 4 Images\n",
    "(Detailed description in the Section 4.2.2 of the Report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b833b65-819d-410b-8691-102ce413fdea",
   "metadata": {},
   "source": [
    "### Read the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02d28d9-1f43-45e4-b389-efcfbd67d9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images:\n",
    "img1 = cv2.imread('Photos/Bedroom/try1_1.jpg')\n",
    "img2 = cv2.imread('Photos/Bedroom/try1_2.jpg')\n",
    "img3 = cv2.imread('Photos/Bedroom/try1_3.jpg')\n",
    "img4 = cv2.imread('Photos/Bedroom/try1_4.jpg')\n",
    "\n",
    "# Convert the images to gray scale:\n",
    "img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "img3 = cv2.cvtColor(img3, cv2.COLOR_BGR2GRAY)\n",
    "img4 = cv2.cvtColor(img4, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Show the images\n",
    "fig = plt.figure(figsize=(40, 80)) \n",
    "fig.add_subplot(1,4,1)\n",
    "plt.title(\"Image 1\")\n",
    "plt.imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))\n",
    "fig.add_subplot(1,4,2)\n",
    "plt.title(\"Image 2\")\n",
    "plt.imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))\n",
    "fig.add_subplot(1,4,3)\n",
    "plt.title(\"Image 3\")\n",
    "plt.imshow(cv2.cvtColor(img3, cv2.COLOR_BGR2RGB))\n",
    "fig.add_subplot(1,4,4)\n",
    "plt.title(\"Image 4\")\n",
    "plt.imshow(cv2.cvtColor(img4, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b7f52b-494b-474d-9381-45a4e5c41ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = [cv2.cvtColor(cv2.imread('Photos/Bedroom/try1_1.jpg'), cv2.COLOR_BGR2RGB), \n",
    "        cv2.cvtColor(cv2.imread('Photos/Bedroom/try1_2.jpg'), cv2.COLOR_BGR2RGB),\n",
    "        cv2.cvtColor(cv2.imread('Photos/Bedroom/try1_3.jpg'), cv2.COLOR_BGR2RGB), \n",
    "        cv2.cvtColor(cv2.imread('Photos/Bedroom/try1_4.jpg'), cv2.COLOR_BGR2RGB)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462b1f22-3c24-412e-8522-78cdcd8413b6",
   "metadata": {},
   "source": [
    "### Stitch the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027a7061-057d-49db-ab0f-cfda5845e329",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = stitch_images(imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cade72d-c54a-4556-ad10-6e9c5282360c",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807c2674-323d-4d2c-a19b-ff5ac423dca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Result image\")\n",
    "plt.imshow(result)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6cffb7-a50e-4087-bd2a-1ab737bb6509",
   "metadata": {},
   "source": [
    "## Image alignment for panorama using OpenCV function - 10 Images\n",
    "(Detailed description in the Section 4.2.2 of the Report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67bbb8c-cc7e-4ab0-90e1-0ae425c1b908",
   "metadata": {},
   "source": [
    "### Read the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf1c7f9-f971-4f36-9ce2-9620d88ad898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images:\n",
    "imgs = []\n",
    "for i in range(1, 11):\n",
    "    file_name = 'Photos/Genova/3/img_{}.jpg'.format(i)\n",
    "    imgs.append(cv2.imread(file_name))\n",
    "\n",
    "# Convert the images to gray scale:\n",
    "for i in range(len(imgs)):\n",
    "    imgs[i] = cv2.cvtColor(imgs[i], cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# plot the images:\n",
    "num_rows, num_cols = 2, 5\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(20, 8))\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    # show image\n",
    "    if i < len(imgs):\n",
    "        ax.imshow(cv2.cvtColor(imgs[i], cv2.COLOR_BGR2RGB))\n",
    "        ax.axis('off')\n",
    "    # hide empty subplots\n",
    "    else:\n",
    "        ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bff683-1fff-465f-856d-96e5514dffcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "for i in range(1, 11):\n",
    "    file_name = 'Photos/Genova/3/img_{}.jpg'.format(i)\n",
    "    imgs.append(cv2.cvtColor(cv2.imread(file_name), cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93042ac-6e1a-4d3b-aace-9e60ac3cde20",
   "metadata": {},
   "source": [
    "### Stitch the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfede11-246d-4d90-8ed3-457ca6ba23fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = stitch_images(imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719d573a-7291-4e50-8b71-53857ca65bbb",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3edb2c-cd02-42aa-a0a4-c78c608905c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "ax.set_title(\"Result image\")\n",
    "ax.imshow(result)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4509fb7-1d1f-4ef2-b134-b3efc285bd9e",
   "metadata": {},
   "source": [
    "## Optical Character Recognition (OCR)\n",
    "(Detailed description in the Section 4.3 of the Report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5227a0a4-877b-4f29-a3e5-07775cd9cc17",
   "metadata": {},
   "source": [
    "### Read the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1454aba9-0f2e-4a9c-970f-68330d533bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_cover = cv2.imread('Photos/Book/book_cover.jpeg')\n",
    "book_test = cv2.imread('Photos/Book/img_2.jpg')\n",
    "\n",
    "# Convert the images to gray scale:\n",
    "book_cover = cv2.cvtColor(book_cover, cv2.COLOR_BGR2GRAY)\n",
    "book_test = cv2.cvtColor(book_test, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Show the images\n",
    "plot_2(book_cover, book_test, \"Book cover\", \"Test image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b464cd-9b0b-4a3e-a04b-41c3f449b72d",
   "metadata": {},
   "source": [
    "### Localization and Description of Keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfce5e7-2069-4a85-8d56-dfcea09b2504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate SIFT detector:\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "# Find the keypoints and descriptors with SIFT:\n",
    "kp1, des1 = sift.detectAndCompute(book_cover, None)\n",
    "kp2, des2 = sift.detectAndCompute(book_test, None)\n",
    "\n",
    "print(\"Number of keypoints book cover:\", len(kp1))\n",
    "print(\"Number of keypoints test image:\", len(kp2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c12666a-355e-40a5-8f98-15cd1d24fe78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the keypoints on the poster image:\n",
    "sift_book_cover = None\n",
    "sift_book_cover = cv2.drawKeypoints(book_cover, kp1, sift_book_cover, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "cv2.imwrite('Outputs/Outputs_book/sift_book_cover.jpg', sift_book_cover)\n",
    "\n",
    "# Draw the keypoints on the test image:\n",
    "sift_book_test = None\n",
    "sift_book_test = cv2.drawKeypoints(book_test, kp2, sift_book_test, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "cv2.imwrite('Outputs/Outputs_form/sift_book_test.jpg', sift_book_test)\n",
    "\n",
    "# Show the result of keypoint detection:\n",
    "plot_2(sift_book_cover, sift_book_test, \"Book cover keypoints\", \"Test image keypoints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652fdd2f-a077-4225-824a-c81400a92e53",
   "metadata": {},
   "source": [
    "### Feature Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3080845-5567-4238-834f-d8133490db47",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_list = []\n",
    "good = []\n",
    "good_list, good = featureMatching(des1, des2, good_list, good)\n",
    "\n",
    "n_of_good_matches  = len(good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbb9483-f3ce-4304-af67-3c450481827b",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_book = None\n",
    "match_book = cv2.drawMatchesKnn(book_cover, kp1, book_test, kp2, good_list, match_book, flags=2)\n",
    "plt.figure(figsize = (50, 100))\n",
    "plt.title(\"Matches\")\n",
    "plt.imshow(cv2.cvtColor(match_book, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e58277b-c0a6-4582-b307-2ce12b0f408d",
   "metadata": {},
   "source": [
    "### Find Homography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0897d8-b225-4aea-864f-eb3308598147",
   "metadata": {},
   "outputs": [],
   "source": [
    "homography = findHomography(n_of_good_matches, good, kp1, kp2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa162920-4605-4143-b9ef-e05d9fbd3229",
   "metadata": {},
   "source": [
    "### Warp perspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf0b9ea-b825-4fc0-824c-149d009ba606",
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_book = cv2.warpPerspective(book_test, homography, (book_cover.shape[1], book_cover.shape[0]))\n",
    "cv2.imwrite('Outputs/Outputs_book/aligned_book.jpg', aligned_book)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32755a26-872b-4c11-b4c6-36569f473dc2",
   "metadata": {},
   "source": [
    "### Alignment result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3c4f79-39ee-4078-ac6a-45de188fbf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the result\n",
    "plot_3(book_cover, book_test, aligned_book, \"Book cover\", \"Test image\", \"Aligned book\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2bd488-b9cc-4620-8c05-427cd3f59fd1",
   "metadata": {},
   "source": [
    "### Text Detection with Pytesseract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9758f1-b31a-4ca1-8a16-18c68912ebf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install pytesseract\n",
    "import pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7d6c63-6389-4862-9457-0a67121cef28",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_cover_text = pytesseract.image_to_string(aligned_book)\n",
    "print(book_cover_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c231163c-3485-4be4-bd35-921b951e9189",
   "metadata": {},
   "source": [
    "## Feature detectors comparison\n",
    "(Detailed description in the Section 5 of the Report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74eaf151-e27e-4f06-bf6f-aa4ed8c16fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the input image\n",
    "image = cv2.imread(\"Photos/Draw2/img1.jpg\")\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bf9d0f-cfe8-4460-b175-c3caa5bd8c7e",
   "metadata": {},
   "source": [
    "### Time comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aecb44f-b86f-41c1-944f-b77523025398",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffeb24c-b5f1-468a-9f51-174bcd7c8000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the needed time for each feature detector:\n",
    "start = time.time()\n",
    "harris = cv2.cornerHarris(image, blockSize=2, ksize=3, k=0.04)\n",
    "end = time.time()\n",
    "harris_time = end - start\n",
    "\n",
    "start = time.time()\n",
    "shi_tomasi = cv2.goodFeaturesToTrack(image, maxCorners=10000, qualityLevel=0.01, minDistance=10)\n",
    "end = time.time()\n",
    "shi_tomasi_time = end - start\n",
    "\n",
    "start = time.time()\n",
    "sift = cv2.SIFT_create()\n",
    "sift_keypoints, sift_descriptors = sift.detectAndCompute(image, None)\n",
    "end = time.time()\n",
    "sift_time = end - start\n",
    "\n",
    "start = time.time()\n",
    "orb = cv2.ORB_create()\n",
    "orb_keypoints, orb_descriptors = orb.detectAndCompute(image, None)\n",
    "end = time.time()\n",
    "orb_time = end - start\n",
    "\n",
    "start = time.time()\n",
    "surf = cv2.xfeatures2d.SURF_create()\n",
    "surf_keypoints, surf_descriptors = surf.detectAndCompute(image, None)\n",
    "end = time.time()\n",
    "surf_time = end - start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b0d5da-279f-4618-a1c7-48e14db78bee",
   "metadata": {},
   "source": [
    "### Number of keypoints comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec61a33-ce0a-4c11-a74a-e2ea33d7f5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of detected features for each feature detector:\n",
    "detected_features = [\n",
    "    len(harris),\n",
    "    len(shi_tomasi),\n",
    "    len(sift_keypoints),\n",
    "    len(orb_keypoints),\n",
    "    len(surf_keypoints)\n",
    "]\n",
    "\n",
    "print('Harris keypoints:', len(harris))\n",
    "print('Shi-Tomasi keypoints:', len(shi_tomasi))\n",
    "print('SIFT keypoints:', len(sift_keypoints))\n",
    "print('ORB keypoints:', len(orb_keypoints))\n",
    "print('SURF keypoints:', len(surf_keypoints))\n",
    "\n",
    "    \n",
    "# Plot the chart\n",
    "labels = ['Harris', 'Shi-Tomasi', 'SIFT', 'ORB', 'SURF']\n",
    "plt.bar(labels, detected_features)\n",
    "plt.xlabel('Feature Detectors')\n",
    "plt.ylabel('Number of Detected Features')\n",
    "plt.title('Comparison number of keypoints')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171c580a-87d4-42b8-998a-516bcccc4158",
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_time = [(\"Harris time:\", harris_time),\n",
    "                  (\"Shi-Tomasi time:\", shi_tomasi_time),\n",
    "                  (\"SIFT time:\", sift_time),\n",
    "                  (\"ORB time:\", orb_time),\n",
    "                  (\"SURF time:\", surf_time)]\n",
    "\n",
    "for item in detection_time:\n",
    "    print(item[0], item[1])\n",
    "\n",
    "# Extract labels and times from the detection_time list\n",
    "labels = [item[0] for item in detection_time]\n",
    "times = [item[1] for item in detection_time]\n",
    "\n",
    "# Plot the chart\n",
    "plt.bar(labels, times)\n",
    "plt.xlabel('Feature Detectors')\n",
    "plt.ylabel(\"Time\")\n",
    "plt.title(\"Comparison Detection Time\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea64082-7672-45e2-8c95-eda9856c82ec",
   "metadata": {},
   "source": [
    "## Feature matcher comparison\n",
    "(Detailed description in the Section 6 of the Report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c91ce9f-deec-4499-8a8a-f8876212fbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the input image\n",
    "image1 = cv2.imread(\"Photos/Genova/1/img_3.jpg\")\n",
    "image2 = cv2.imread(\"Photos/Genova/1/img_4.jpg\")\n",
    "\n",
    "# Conver to gray\n",
    "image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "image2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Show the images\n",
    "plot_2(image1, image2, \"Image 1\", \"Image 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b196e8-c008-4cbc-96af-80a40ae0d6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate SIFT detector:\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "# Find the keypoints and descriptors with SIFT:\n",
    "kp1, des1 = sift.detectAndCompute(image1, None)\n",
    "kp2, des2 = sift.detectAndCompute(image2, None)\n",
    "\n",
    "print(len(kp1))\n",
    "print(len(kp2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5579dca2-6803-487c-bf21-44366090e6b8",
   "metadata": {},
   "source": [
    "### Brute Force Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf8f369-766f-49bb-921f-e197f83243f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BFMatcher with default params\n",
    "start = time.time()\n",
    "bf = cv2.BFMatcher()\n",
    "matches = bf.knnMatch(des1, des2, k=2)\n",
    "end = time.time()\n",
    "bf_time = end - start\n",
    "\n",
    "# Apply ratio test\n",
    "good_list = []\n",
    "good = []\n",
    "for m,n in matches:\n",
    "    if m.distance < 0.75 * n.distance:\n",
    "        good_list.append([m])\n",
    "        good.append(m)\n",
    "\n",
    "print(\"Number of good matches with BF Matcher:\", len(good))\n",
    "\n",
    "# cv.drawMatchesKnn expects list of lists as matches.\n",
    "result_bf = cv2.drawMatchesKnn(image1, kp1, image2, kp2, good_list, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "plt.figure(figsize = (50, 100))\n",
    "plt.title(\"Matches\")\n",
    "plt.imshow(result_bf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73ba207-9502-4982-9a59-06cc46687233",
   "metadata": {},
   "source": [
    "### FLANN Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d56390b-3769-4db5-a024-b88486d8cb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAN_INDEX_KDTREE = 0\n",
    "index_params = dict (algorithm = FLAN_INDEX_KDTREE, trees=5)\n",
    "search_params = dict (checks=50)\n",
    "\n",
    "start = time.time()\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "matches = flann.knnMatch(des1, des2, k=2)\n",
    "end = time.time()\n",
    "flann_time = end - start\n",
    "\n",
    "good_matches = []\n",
    "for m1, m2 in matches:\n",
    "  if m1.distance < 0.75 * m2.distance:\n",
    "    good_matches.append([m1])\n",
    "\n",
    "print(\"Number of good matches with FLANN Matcher:\", len(good_matches))\n",
    "\n",
    "\n",
    "flann_matches = cv2.drawMatchesKnn(image1, kp1, image2, kp2, good_matches, None, flags=2)\n",
    "plt.figure(figsize = (50, 100))\n",
    "plt.title(\"Matches\")\n",
    "plt.imshow(flann_matches)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be5ba64-abf7-4353-9967-6c458bc52fa1",
   "metadata": {},
   "source": [
    "### Time comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6b7307-cfc9-4608-a6fe-b78f1752ad58",
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_time = [(\"BF Matcher time:\", bf_time),\n",
    "                  (\"FLANN Matcher time:\", flann_time)]\n",
    "\n",
    "for item in matching_time:\n",
    "    print(item[0], item[1])\n",
    "\n",
    "# Extract labels and times from the detection_time list\n",
    "labels = [item[0] for item in matching_time]\n",
    "times = [item[1] for item in matching_time]\n",
    "\n",
    "# Plot the chart\n",
    "plt.bar(labels, times)\n",
    "plt.xlabel('Matcher')\n",
    "plt.ylabel(\"Time\")\n",
    "plt.title(\"Comparison Matching Time\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
